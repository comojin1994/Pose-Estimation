{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "GPU = f'0'\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=GPU\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflowjs as tfjs\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.callbacks import (\n",
    "    ReduceLROnPlateau,\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    TensorBoard\n",
    ")\n",
    "from tensorflow.keras.backend import set_learning_phase\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from config import *\n",
    "from utils import helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Seed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = f'../Datasets/HomePT/'\n",
    "tfjs_target_dir = f'./checkpoints/best_model_js/'\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "classes = 3\n",
    "\n",
    "learning_rate = 5e-5\n",
    "wd = 0.0005\n",
    "max_lr = 2e-3\n",
    "min_lr = 5e-5\n",
    "cycle_len = 20\n",
    "\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255.,\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1./255.,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1410 images belonging to 3 classes.\n",
      "Found 90 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    IMAGE_PATH+f'train/',\n",
    "    target_size=[480,480],\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    IMAGE_PATH+f'val/',\n",
    "    target_size=[480,480],\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-37312bf9b745>:1: set_learning_phase (from tensorflow.python.keras.backend) is deprecated and will be removed after 2020-10-11.\n",
      "Instructions for updating:\n",
      "Simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n"
     ]
    }
   ],
   "source": [
    "# set_learning_phase(0)\n",
    "# class EverySports(tf.keras.Model):\n",
    "#     def __init__(self, model_variant):\n",
    "#         # (RT, I, II, III or IV)\n",
    "#         super(EverySports, self).__init__()\n",
    "#         self.features = load_model(os.path.join('EfficientPose', 'keras', 'EfficientPose{0}.h5'.format(model_variant.upper())),\n",
    "#                    custom_objects={'BilinearWeights': helpers.keras_BilinearWeights,\n",
    "#                                    'Swish': helpers.Swish(helpers.eswish), 'eswish': helpers.eswish,\n",
    "#                                    'swish1': helpers.swish1})\n",
    "#         self.features.trainable = False\n",
    "        \n",
    "#         self.conv = Conv2D(1, 3, 1, padding='same', use_bias=False)\n",
    "#         self.flatten = Flatten()\n",
    "#         self.dense1 = Dense(1024)\n",
    "#         self.dropout1 = Dropout(0.3)\n",
    "#         self.dense2 = Dense(512)\n",
    "#         self.dropout2 = Dropout(0.3)\n",
    "#         self.dense3 = Dense(3)\n",
    "    \n",
    "#     def call(self, x):\n",
    "#         x,_,_,_ = self.features(x)\n",
    "#         x = self.conv(x)\n",
    "#         # x = tf.keras.backend.sum(x, axis=-1)\n",
    "        \n",
    "#         x = self.flatten(x)\n",
    "#         x = self.dense1(x)\n",
    "#         x = self.dropout1(x)\n",
    "#         x = tf.nn.relu(x)\n",
    "        \n",
    "#         x = self.dense2(x)\n",
    "#         x = self.dropout2(x)\n",
    "#         x = tf.nn.relu(x)\n",
    "        \n",
    "#         x = self.dense3(x)\n",
    "#         x = tf.nn.softmax(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# model = EverySports('III')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model_variant = 'III'\n",
    "base_model = load_model(os.path.join('EfficientPose', 'keras', 'EfficientPose{0}.h5'.format(model_variant.upper())),\n",
    "                   custom_objects={'BilinearWeights': helpers.keras_BilinearWeights,\n",
    "                                   'Swish': helpers.Swish(helpers.eswish), 'eswish': helpers.eswish,\n",
    "                                   'swish1': helpers.swish1})\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-5961966c1961>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m ])\n",
      "\u001b[0;32m~/anaconda3/envs/EfficientPose/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/EfficientPose/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layers, name)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/EfficientPose/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/EfficientPose/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSINGLE_LAYER_OUTPUT_ERROR_MSG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_source_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API."
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    Conv2D(1, 3, 1, padding='same', use_bias=False),\n",
    "    Flatten(),\n",
    "    Dense(1024, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tfa.optimizers.AdamW(learning_rate, wd)\n",
    "\n",
    "model.compile(\n",
    "    optimizer = optimizer,\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Callbacks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = './checkpoints/best_model.h5'\n",
    "mon = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath, save_weights_only=False,\n",
    "                                                monitor='val_accuracy', mode='max', save_best_only=True,\n",
    "                                        verbose=1)\n",
    "\n",
    "def trianfle_fn(x):\n",
    "    return 1. / (2.**(x - 1))\n",
    "clr_f = tfa.optimizers.CyclicalLearningRate(\n",
    "    initial_learning_rate = max_lr,\n",
    "    maximal_learning_rate = min_lr,\n",
    "    step_size = cycle_len,\n",
    "    scale_fn = trianfle_fn\n",
    ")\n",
    "\n",
    "clr = tf.keras.callbacks.LearningRateScheduler(clr_f)\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, patience=5, \n",
    "                                          verbose=2, mode='auto', baseline=None, \n",
    "                                          restore_best_weights=True)\n",
    "\n",
    "callbacks = [mon, clr, es]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0836 - accuracy: 0.9681\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.97778, saving model to ./checkpoints/best_model.h5\n",
      "89/89 [==============================] - 19s 214ms/step - loss: 0.0836 - accuracy: 0.9681 - val_loss: 0.1233 - val_accuracy: 0.9778\n",
      "Epoch 2/100\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 0.9972\n",
      "Epoch 00002: val_accuracy improved from 0.97778 to 1.00000, saving model to ./checkpoints/best_model.h5\n",
      "89/89 [==============================] - 17s 190ms/step - loss: 0.0075 - accuracy: 0.9972 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "89/89 [==============================] - ETA: 0s - loss: 7.4379e-05 - accuracy: 1.0000\n",
      "Epoch 00003: val_accuracy did not improve from 1.00000\n",
      "89/89 [==============================] - 17s 187ms/step - loss: 7.4379e-05 - accuracy: 1.0000 - val_loss: 1.9602e-06 - val_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "89/89 [==============================] - ETA: 0s - loss: 2.1922e-07 - accuracy: 1.0000\n",
      "Epoch 00004: val_accuracy did not improve from 1.00000\n",
      "89/89 [==============================] - 17s 188ms/step - loss: 2.1922e-07 - accuracy: 1.0000 - val_loss: 2.3165e-06 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "89/89 [==============================] - ETA: 0s - loss: 2.2794e-06 - accuracy: 1.0000\n",
      "Epoch 00005: val_accuracy did not improve from 1.00000\n",
      "89/89 [==============================] - 17s 189ms/step - loss: 2.2794e-06 - accuracy: 1.0000 - val_loss: 2.5482e-06 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "89/89 [==============================] - ETA: 0s - loss: 3.4077e-07 - accuracy: 1.0000\n",
      "Epoch 00006: val_accuracy did not improve from 1.00000\n",
      "89/89 [==============================] - 17s 189ms/step - loss: 3.4077e-07 - accuracy: 1.0000 - val_loss: 2.8264e-06 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "89/89 [==============================] - ETA: 0s - loss: 1.3350e-07 - accuracy: 1.0000\n",
      "Epoch 00007: val_accuracy did not improve from 1.00000\n",
      "Restoring model weights from the end of the best epoch.\n",
      "89/89 [==============================] - 17s 191ms/step - loss: 1.3350e-07 - accuracy: 1.0000 - val_loss: 3.2237e-06 - val_accuracy: 1.0000\n",
      "Epoch 00007: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = f'../Datasets/HomePT/val/0/0.jpg'\n",
    "img = cv2.imread(file_path)\n",
    "h, w = img.shape[0], img.shape[1]\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "img = cv2.resize(img, dsize=(480, 480), interpolation=cv2.INTER_AREA)\n",
    "img /= 255.\n",
    "img = img[np.newaxis, ...]\n",
    "\n",
    "output = model.predict(img)\n",
    "\n",
    "# output = np.sum(output[0], -1)\n",
    "# plt.imshow(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9976629e-01, 5.1712132e-15, 2.3375664e-04]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert tf model to tfjs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Saving the model to HDF5 format requires the model to be a Functional model or a Sequential model. It does not work for subclassed models, because such models are defined via the body of a Python method, which isn't safely serializable. Consider saving to the Tensorflow SavedModel format (by setting save_format=\"tf\") or using `save_weights`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-09f9ad85d9cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtfjs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_keras_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtfjs_target_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/EfficientPose/lib/python3.7/site-packages/tensorflowjs/converters/keras_h5_conversion.py\u001b[0m in \u001b[0;36msave_keras_model\u001b[0;34m(model, artifacts_dir, quantization_dtype_map, weight_shard_size_bytes)\u001b[0m\n\u001b[1;32m    339\u001b[0m   \"\"\"\n\u001b[1;32m    340\u001b[0m   \u001b[0mtemp_h5_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmktemp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_h5_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m   topology_json, weight_groups = (\n\u001b[1;32m    343\u001b[0m       h5_merged_saved_model_to_tfjs_format(temp_h5_path))\n",
      "\u001b[0;32m~/anaconda3/envs/EfficientPose/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[1;32m   1977\u001b[0m     \"\"\"\n\u001b[1;32m   1978\u001b[0m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[0;32m-> 1979\u001b[0;31m                     signatures, options)\n\u001b[0m\u001b[1;32m   1980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1981\u001b[0m   def save_weights(self,\n",
      "\u001b[0;32m~/anaconda3/envs/EfficientPose/lib/python3.7/site-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[1;32m    122\u001b[0m         not isinstance(model, sequential.Sequential)):\n\u001b[1;32m    123\u001b[0m       raise NotImplementedError(\n\u001b[0;32m--> 124\u001b[0;31m           \u001b[0;34m'Saving the model to HDF5 format requires the model to be a '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m           \u001b[0;34m'Functional model or a Sequential model. It does not work for '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m           \u001b[0;34m'subclassed models, because such models are defined via the body of '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Saving the model to HDF5 format requires the model to be a Functional model or a Sequential model. It does not work for subclassed models, because such models are defined via the body of a Python method, which isn't safely serializable. Consider saving to the Tensorflow SavedModel format (by setting save_format=\"tf\") or using `save_weights`."
     ]
    }
   ],
   "source": [
    "tfjs.converters.save_keras_model(model, tfjs_target_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EfficientPose",
   "language": "python",
   "name": "efficientpose"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
